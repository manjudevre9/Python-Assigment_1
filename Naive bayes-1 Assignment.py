#Que.1.What is the formula for Bayes'theorem?
#Ans.Bayes'theorem is a fundamental concept in probability theory & statistics.The formula for Bayes'theorem  is:
# P(A|B)=P(B|A)*P(A)/P(B)
# Where:
# P(A|B) is the posterior probability of A give B
# P(B|A) is the likelihood of B give A
# P(A) is the prior probability of A
# P(B) is the prior probability of B

#Que.2 .What is Bayes'theorem?
#Ans.Bayes'theorem is a mathematical formula for determining conditional probability. It describes the 
# probability of an event,based on prior knowledge of conditions that might be ralated to the event.

#Que.3.How is Bayes'theorem used in practice?
#Ans.1.Medical Diagnosis.
# 2.Image & Speech Recognition.
# 3.Spam Filtering.
# 4.Financial Risk Assessment.
# 5.Quality Control.
# 6.Genetics & Genomics.
# 7.Natural Language Processing(NLP).
# 8.Recommendation Systems.
# 9.Fault Detection & Diagnosis.
# 10.Cybersecurity.

#Que.4.What is the relationship between Bayes'theorem & conditional probability?
#Ans.Bayes'theorem is essentially a formula for updating conditional probabilty based on new evidence.
# It allows you to calculate the posterior probability of an event (P(A|B)) given the likelihood of the 
# evidence(P(B|A)),the prior probability of the event (P(A)),& the prior probability of the evidence(P(B)).
# In other words, Bayes'theorem allows you to revise your probability estimates based on new data or evidence,
# which is a fundamental concept in probability theory & statistics.

#Que.5.How do you choose which type of Naive bayes classifier to use for any given problem?
#Ans.1.Gaussian Naive Bayes (GNB):Use When: Features are continuous & follow a Gaussian distribution.
# Assumption:Features are independent & identically distributed(i.i.d.).

# 2.Multinomial Naive Bayes (MNB):Use when:Features are categorical & represent frequencies or counts.
# Assumption:Features are independent & the probability of each feature is proportional to its frequency.

# 3.Bernoulli Naive Bayes(BNB):Use when:Features are binary (0/1,yes/no,etc.).
# Assumption:Features are independent & each feature has binary distribution.

# 4.Complement Naive Bayes (CNB):Use when:Imbalanced datasets, where one class has a significantly larger
# number of instances than others.
# Assumption:Features are independant,but the algorithm focuses on the complement of the majority class.

  